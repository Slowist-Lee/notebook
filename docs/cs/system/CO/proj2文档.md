
好的，这是您提供的文档的简体中文翻译，格式为 Markdown。

---

## 项目 - 缓存组织与性能评估

在本次作业中，你将熟悉缓存（cache）的工作原理以及如何评估其性能。为实现这些目标，你将首先构建一个缓存模拟器并验证其正确性。然后，你将使用你的缓存模拟器来研究讲座中和 Hennessy & Patterson 教材第五章讨论的多种不同缓存组织和管理策略。

第 1 节将引导你如何构建缓存模拟器，第 2 节将详细说明你将使用模拟器进行的性能评估研究。

### 1 缓存模拟器

在本次作业的第一部分，你将构建一个缓存模拟器。你将构建的模拟器类型被称为**踪迹驱动模拟器（trace-driven simulator）**，因为它以事件踪迹（trace of events）作为输入，在本项目中即为内存引用（memory references）。我们将为你提供踪迹文件，这些踪迹是在另一台机器上获取的。获取后，它可以被用来驱动模拟研究。在本次作业中，我们给你的踪迹文件中指定的内存引用事件将被你的模拟器用来驱动数据在缓存中的移入和移出，从而模拟其行为。踪迹驱动模拟器对于研究缓存非常有效。

你的缓存模拟器将能够根据命令行给出的参数进行配置，并且必须支持以下功能：

*   总缓存大小
*   块大小（Block size）
*   统一缓存（Unified） vs. 分离式指令和数据缓存（split I- and D-caches）
*   相联度（Associativity）
*   写回（Write back） vs. 写通（write through）
*   写分配（Write allocate） vs. 非写分配（write no allocate）

除了实现上述功能外，你的模拟器还必须收集并报告若干统计数据，这些数据将用于验证模拟器的正确性，并将在后续的性能评估中使用。具体来说，你的模拟器必须跟踪：

*   指令引用次数
*   数据引用次数
*   指令未命中次数
*   数据未命中次数
*   从内存读取的字（word）数
*   写回（复制）到内存的字（word）数

---
### 1.1 文件

在你的项目中，总共有五个程序文件，如下表所示，其中列出了文件名及其内容的简要描述。

| 文件名 | 描述 |
| :--- | :--- |
| Makefile | 构建模拟器。 |
| main.c | 驱动模拟器的顶层例程。 |
| main.h | `main.c` 的头文件。 |
| cache.c | 缓存模型。 |
| cache.h | `cache.c` 的头文件。 |

"Makefile" 是一个 UNIX 的 make 文件。尝试在你复制了文件的本地目录中输入 `make`。这将从提供的程序文件构建模拟器，并生成一个名为 "sim" 的可执行文件。当然，由于我们给你的文件只是模拟器的模板，这个可执行文件做不了太多事情。但是，你可以使用这个 make 文件来在你添加功能时构建你的模拟器。如果你使用了除了我们给你的四个程序文件之外的额外源文件，请确保更新 make 文件。

四个程序文件，`main.c`, `main.h`, `cache.c`, 和 `cache.h`，包含了一个用 C 语言编写的模拟器模板。这些文件包含许多有用的例程，可以为你节省时间（因为你不必自己编写它们）。

`main.c` 包含了模拟器的顶层驱动程序。它有一个名为 `parse_args()` 的前端例程，用于解析命令行参数，以允许使用前面指定的所有不同参数来配置缓存模型。要查看有效的命令行参数列表，请尝试输入 `sim -h`（在编译模板文件之后）。请注意，你的模拟器代码应将四个大小参数（块大小、统一缓存大小、指令缓存大小和数据缓存大小）解释为以字节（bytes）为单位。`main.c` 还包含一个顶层的“模拟器循环”，名为 `play_trace()`，以及一个从踪迹文件中解析行的例程，名为 `read_trace_element()`。对于读取的每个踪迹元素，`play_trace()` 会通过 `perform_access()` 例程调用缓存模型，以模拟对缓存的单次内存引用。虽然你可以自由修改 `main.c`，但你应该能够在不对此文件进行任何修改的情况下完成作业。

`cache.c` 包含了缓存模型本身。这个文件中有三个你可以直接使用的例程。`set_cache_param()` 是 `main.c` 中参数解析例程的缓存模型接口。它拦截所有的参数请求，并设置在 `cache.c` 中声明为静态全局变量的相应参数值。`delete` 和 `insert` 是用于双向链表数据结构的删除和插入例程，我们将在下面解释。`dump_settings()` 根据配置的参数打印缓存配置，`print_stats()` 打印你将收集的统计信息。除了这五个例程之外，还有三个模板函数需要你来编写。`init_cache()` 会被调用一次，用于构建和初始化缓存模型数据结构。`perform_access()` 在模拟器循环的每次迭代中被调用一次，以模拟对缓存的单次内存引用。而 `flush()` 在模拟结束时被调用，以清除缓存中的内容。请注意，在所有脏缓存行（dirty cache lines）（如果有的话）都被刷新出缓存之前，模拟并未结束，并且所有统计数据都会在这些刷新操作后更新。

---
`main.h` 是自解释的。`cache.h` 包含一些用于初始化和更改缓存配置的常量，并包含了用于实现缓存模型的数据结构（我们将在下一节中解释这些）。最后，`cache.h` 还包含一个用于计算以 2 为底的对数的宏，名为 `LOG2`，这在你构建缓存模型时应该会很有用。

除了这五个程序文件，还有三个你将用来驱动模拟器的踪迹文件。它们的名字是 “spice.trace”、“cc.trace” 和 "tex.trace"。这些文件分别是跟踪 spice 电路模拟器、一个 C 编译器和 TeX 文本格式化程序的内存引用行为的结果。它们各自大约代表 100 万次内存引用。

踪迹文件是 ASCII 格式，因此是人类可读的。踪迹文件中的每一行代表一次内存引用，并包含两个数字：一个引用类型（一个介于 0-2 之间的数字）和一个内存地址。你的模拟器应忽略这两个数字之后的所有其他文本。引用编号指定了正在执行的内存引用类型，编码如下：

*   0 数据加载引用 (Data load reference)
*   1 数据存储引用 (Data store reference)
*   2 指令加载引用 (Instruction load reference)

引用类型后面的数字是内存引用本身的字节地址。这个数字是十六进制格式的，并指定了一个 32 位的字节地址，范围在 0-0xffffffff（含）之间。

### 1.2 构建缓存模型

构建缓存模型有很多种方法。你将仅根据模型的正确性进行评分，因此你可以完全自由地以任何你选择的方式实现缓存模型。在本节中，我们为使用模板代码中给出的数据结构的实现提供一些提示。

#### 1.2.1 增量方法

最重要的提示是一条通用的软件工程经验法则：**通过增量添加功能来构建模拟器**。你能犯下的最大错误是试图一次性实现所有缓存功能。相反，应该先构建最简单的缓存模型，并在继续之前对其进行彻底测试。然后，添加一小部分功能，再对其进行彻底测试。如此循环，直到你完成作业。我们推荐以下增量方法：

1.  构建一个统一的、固定块大小、直接映射（direct-mapped）的缓存，采用写回（write-back）写策略和写分配（write allocate）分配策略。
2.  添加可变块大小功能。
3.  添加可变相联度功能。
4.  添加分离式组织功能。
5.  添加写通（write through）写策略功能。
6.  添加非写分配（write no-allocate）分配策略功能。

在每个阶段，你都可以通过将模拟器得到的结果与我们将提供的验证数据进行比较来测试你的缓存模型。

---
#### 1.2.2 缓存结构

在 `cache.h` 中，你会找到实现大部分缓存模型的 `cache` 数据结构：
```c
typedef struct cache_ {
  int size;                 /* cache size in words */
  int associativity;        /* cache associativity */
  int n_sets;               /* number of cache sets */
  unsigned index_mask;      /* mask to find cache index */
  int index_mask_offset;    /* number of zero bits in mask */
  Pcache_line *LRU_head;    /* head of LRU list for each set */
  Pcache_line *LRU_tail;    /* tail of LRU list for each set */
  int *set_contents;        /* number of valid entries in set */
} cache, *Pcache;
```
这个结构的前六个字段是缓存配置常量，你应该在 `init_cache()` 中初始化它们。请查阅讲座和课本以了解这些常量是如何计算的。剩下的三个字段，`LRU_head`、`LRU_tail` 和 `set_contents`，是实现缓存的主要结构。让我们首先考虑如何实现最简单的情况，即直接映射缓存。在这种情况下，你只需要 `LRU_head` 字段。

一旦你计算出缓存中的组数 `n_sets`，你应该分配一个缓存行指针数组：
```c
my_cache.LRU_head =
  (Pcache_line *)malloc(sizeof(Pcache_line)*my_cache.n_sets);
```

`LRU_head` 数组是跟踪缓存中所有缓存行的数据结构：该数组中的每个元素都是一个指向占据该组的缓存行的指针，如果该组中没有有效的缓存行，则为 NULL 指针（初始时，数组中的所有元素都应设置为 NULL）。缓存行本身保存在 `cache_line` 数据结构中，该结构也在 `cache.h` 中声明：

---
```c
typedef struct cache_line_ {
  unsigned tag;
  int dirty;

  struct cache_line_ *LRU_next;
  struct cache_line_ *LRU_prev;
} cache_line, *Pcache_line;
```

这个结构非常简单。<u>"tag" 字段应设置为缓存行中缓存的地址的标签部分，"dirty" 字段应在每次写入缓存行时设置</u>。当替换缓存行时，应查阅 "dirty" 字段。如果该字段被设置，则必须将缓存行写回内存。虽然你不会模拟这个过程（因为你不会模拟主存），但这会影响你的缓存统计。剩下的两个字段对于直接映射缓存不是必需的，将在后面讨论。请注意，在这个模拟器中，你不需要跟踪任何数据。我们只模拟内存引用模式——我们不关心与这些引用相关的数据。

最后一个提示：如果你正确计算了 `index_mask` 和 `index_mask_offset` 字段，那么你应该能够通过以下方式计算地址 `addr` 在缓存中的索引 `index`：

`index = (addr & my_cache.index_mask) >> my_cache.index_mask_offset`

然后，检查此索引处的缓存行 `my_cache.LRU_head[index]`。如果该缓存行的标签与地址的标签匹配，那么你就有一次缓存命中。否则，你就有一次缓存未命中¹。

#### 1.2.3 增加相联度和 LRU 替换

一旦你构建了直接映射缓存，你可以通过允许每个组中驻留多个缓存行来将其扩展为处理组相联（set-associative）缓存。我们提供的 `cache` 和 `cache_line` 数据结构旨在通过将每个组实现为 `cache_line` 数据结构的双向链表来处理这种情况。因此，如果你的模拟器需要向一个已经包含一个缓存行的组中添加一个新的缓存行，只需将新的缓存行插入到链表中即可。然而，你的模拟器绝不能允许每个链表中的缓存行数量超过配置的相联度。为了强制执行这一点，为 `cache` 数据结构中的 `set_contents` 字段分配一个整数数组，每组一个整数。使用这些整数作为计数器来计算每个组中的缓存行数量，并确保任何计数器都不会超过缓存的相联度。

如果你需要向一个已经满容量的组中插入一个缓存行，那么必须驱逐（evict）其中一个缓存行。在直接映射缓存的情况下，驱逐很容易，因为每个组中最多只有一个缓存行。当缓存具有更高的相联度时，就有必要选择一个缓存行进行替换。在本次作业中，你将实现一个 LRU（最近最少使用）替换

¹当然，如果索引处的指针是 NULL，你也有一次缓存未命中。

---
策略。实现 LRU 的一种方法是，根据缓存行被引用的顺序，保持每个组中的链表有序。这可以通过每次引用缓存行时将其从链表中移除，然后重新插入到链表的头部来完成。在这种情况下，你应该总是驱逐位于链表尾部的缓存行。

要构建组相联缓存并实现上述 LRU 替换策略，你应该使用 `cache.c` 模块中提供的两个例程 `delete` 和 `insert`。`delete` 从链表中移除一个项，而 `insert` 在链表的头部插入一个项。这两个例程都假定一个双向链表（我们的数据结构提供了这一点），并接受三个参数：一个头指针（通过引用传递），一个尾指针（通过引用传递），以及一个要插入或删除的缓存行的指针（通过值传递）。

最后一个提示：如果你实现了一个可以配置相联度的组相联缓存，那么你也已经实现了一个全相联（fully associative）缓存。全相联缓存只是一个 N 路组相联缓存，其中只有 1 个组，而 N 是缓存中的总缓存行数。

### 1.3 验证

在第 2 节中，你将使用你的缓存模拟器来分析我们为你提供的踪迹上各种缓存配置的特性和性能。在进行此操作之前，验证你的缓存模拟器的**准确性**非常重要。

将你的缓存模拟器的输出与表 1 中提供的验证统计数据进行比较。该表显示了在 spice 工作负载踪迹（类目录中的文件 "spice.trace"）上，给定各种缓存配置，在一个正常工作的缓存模拟器上获得的统计数据。你的模拟器生成的统计数据应与表 1 中报告的统计数据完全匹配。请注意，在表 1 中，标记为 "CS" 和 "BS" 的列中的值以字节为单位，而标记为 "DF" 和 "CB" 的列中的值以字为单位。²

### 2 性能评估

现在你应该有一个可以配置的缓存模拟器（可配置总大小、块大小、统一与分离、相联度、写通与写回、写分配与非写分配）。此外，这个模拟器应该已经根据我们给你的样本缓存统计数据进行了验证。（如果你还没有这样的缓存模拟器，请不要尝试这部分的作业，直到你有了为止）。现在你将使用你的缓存模拟器对我们提供的三个样本踪迹（spice、gcc 和 TeX）进行研究。

²请记住，我们假设一个 32 位架构，所以一个字包含 4 个字节。

---
**表 1：来自 spice 工作负载的用于验证的样本统计数据。**
列 "CS" 表示缓存大小（字节）。列 "I- vs D-" 表示分离式或统一缓存。列 "BS" 表示块大小（字节）。列 "Ass" 表示相联度。列 "Write" 表示写策略，写回 ("WB") 或写通 ("WT")。列 "Alloc" 表示分配策略，写分配 ("WA") 或非写分配 ("WNA")。最后六列显示了验证统计数据。它们分别是指令未命中数、指令替换数、数据未命中数、数据替换数、以字为单位的总按需读取数，以及以字为单位的总写回数。

| CS   | I- vs D- | BS  | Ass | Write | Alloc | Instructions |          | Data       |          | Total   |        |
| :--- | :------- | :-: | :-: | :---: | :---: | :----------- | :------- | :--------- | :------- | :------ | :----- |
|      |          |     |     |       |       | **Misses**   | **Repl** | **Misses** | **Repl** | **DF**  | **CB** |
| 8 K  | Split    | 16  |  1  |  WB   |  WA   | 24681        | 24173    | 8283       | 7818     | 131856  | 12024  |
| 16 K | Split    | 16  |  1  |  WB   |  WA   | 11514        | 10560    | 5839       | 5051     | 69412   | 8008   |
| 32 K | Split    | 16  |  1  |  WB   |  WA   | 5922         | 4321     | 1567       | 520      | 29956   | 3628   |
| 64 K | Split    | 16  |  1  |  WB   |  WA   | 2619         | 484      | 1290       | 103      | 15636   | 3324   |
| 8 K  | Unified  | 16  |  1  |  WB   |  WA   | 36136        | 35787    | 21261      | 21098    | 229588  | 37844  |
| 8 K  | Unified  | 32  |  1  |  WB   |  WA   | 26673        | 26502    | 19561      | 19476    | 369872  | 69104  |
| 8 K  | Unified  | 64  |  1  |  WB   |  WA   | 23104        | 23029    | 20377      | 20324    | 695696  | 136112 |
| 32 K | Split    | 128 |  1  |  WB   |  WA   | 1964         | 1726     | 459        | 280      | 77536   | 7296   |
| 8 K  | Split    | 64  |  2  |  WB   |  WA   | 6590         | 6462     | 3160       | 3032     | 156000  | 18880  |
| 8 K  | Split    | 64  |  4  |  WB   |  WA   | 6025         | 5897     | 875        | 747      | 110400  | 7296   |
| 8 K  | Split    | 64  |  8  |  WB   |  WA   | 6435         | 6307     | 803        | 675      | 115808  | 6656   |
| 8 K  | Split    | 64  | 16  |  WB   |  WA   | 6536         | 6408     | 799        | 671      | 117360  | 6624   |
| 8 K  | Split    | 64  | 128 |  WB   |  WA   | 6523         | 6395     | 790        | 662      | 117008  | 6576   |
| 1 K  | Split    | 64  |  2  |  WB   |  WA   | 44962        | 44946    | 24767      | 24751    | 1115664 | 149200 |
| 1 K  | Split    | 64  |  8  |  WB   |  WA   | 45885        | 45869    | 22808      | 22792    | 1099088 | 112480 |
| 1 K  | Split    | 64  | 16  |  WB   |  WA   | 45969        | 45953    | 20667      | 20651    | 1066176 | 90416  |
| 8 K  | Split    | 16  |  1  |  WT   |  WA   | 24681        | 24173    | 8283       | 7818     | 131856  | 66538  |
| 8 K  | Split    | 32  |  1  |  WT   |  WA   | 15868        | 15612    | 7504       | 7264     | 186976  | 66538  |
| 8 K  | Split    | 64  |  2  |  WT   |  WA   | 6590         | 6462     | 3160       | 3032     | 156000  | 66538  |
| 8 K  | Split    | 16  |  1  |  WB   |  WNA  | 24681        | 24173    | 14904      | 6688     | 127304  | 14643  |
| 8 K  | Split    | 32  |  1  |  WB   |  WNA  | 15868        | 15612    | 15098      | 6421     | 180200  | 22033  |
| 8 K  | Split    | 64  |  2  |  WB   |  WNA  | 6590         | 6462     | 8638       | 2726     | 151104  | 13624  |

---
### 2.1 工作集（Working Set）特征分析

在这个性能评估练习中，你将分析给定的三个样本踪迹的工作集大小。

使用你的缓存模拟器，绘制缓存的命中率（hit rate）随缓存大小变化的函数图。从 4 字节的缓存大小开始，然后每次将大小乘以 2，直到命中率对缓存大小不再敏感。使用分离式缓存组织，这样你可以分别表征指令和数据引用的行为（也就是说，每个样本踪迹你将有两个图——一个用于指令，一个用于数据）。通过**始终**使用全相联缓存来排除冲突未命中（conflict misses）的影响。此外，始终将块大小设置为 4 字节，使用写回缓存，并使用写分配策略。

回答以下问题：
1.  解释这个实验在做什么，以及它是如何工作的。同时，解释命中率 vs. 缓存大小图中特征的重要性。
2.  对于这三个样本踪迹，总的指令工作集大小和数据工作集大小分别是多少？

---

记录：

```c
    switch (access_type) {
    case TRACE_DATA_LOAD:
    case TRACE_DATA_STORE:
    case TRACE_INST_LOAD:
      perform_access(addr, access_type);
      break;
    default:
      printf("skipping access, unknown type(%d)\n", access_type);
    }
```


然后翻到

```c
#define TRACE_DATA_LOAD 0
#define TRACE_DATA_STORE 1
#define TRACE_INST_LOAD 2
```

* `TRACE_DATA_LOAD` 几乎可以肯定是 `0` (数据加载) 
* `TRACE_DATA_STORE` 几乎可以肯定是 `1` (数据存储) 
* `TRACE_INST_LOAD` 几乎可以肯定是 `2` (指令加载)

构建的第一个cache:

```c
void init_cache()

{

  int size = cache_usize/4;

  int associativity = cache_assoc;

  int n_sets = cache_usize/(cache_block_size*cache_assoc);

  int index_mask_offset=LOG2(cache_block_size);

  int index_mask = n_sets-1;

  /* initialize the cache, and cache statistics data structures */

  

  //对于直接映射缓存来说

  

  c1.LRU_head =

  (Pcache_line *)malloc(sizeof(Pcache_line)*c1.n_sets);

  

}

/************************************************************/

  

/************************************************************/

void perform_access(addr, access_type)

  unsigned addr, access_type;

{

  /* handle an access to the cache */

  //解析index

  int index = (addr & c1.index_mask) >> c1.index_mask_offset;

  int current_tag = addr >> (c1.index_mask_offset + LOG2(c1.n_sets));

  

  if (c1.LRU_head[index] && c1.LRU_head[index]->tag==current_tag){

    /* hit handling */

    //根据LRU规则

    delete(c1.LRU_head,c1.LRU_tail,c1.LRU_head[index]);

    insert(c1.LRU_head,c1.LRU_tail,c1.LRU_head[index]);

  

    if (access_type==1){

      //写操作

      //Write-back操作

      c1.LRU_head[index]->dirty=1;//dirty设成1，说明缓存比主存新

    }

    else{

  

    }

  }

  else{

    /*miss handling */

    c1.LRU_head[index]->tag=current_tag;

    /*if empty*/

    if(c1.LRU_head[index]==NULL){

      //放进Cache里，给他分配一个cache_line

      c1.LRU_head[index]=(Pcache_line*)malloc(sizeof(Pcache_line));

      //放入tag

      c1.LRU_head[index]->tag=current_tag;

    }

    else{

    }

    if(access_type==1){

      /*写操作*/

      c1.LRU_head[index]->dirty=1;

    }
  }
}

/************************************************************/
/************************************************************/

void flush()

{

  /* flush the cache */

}
```

为了测试正确与否，好像只能先写一个次数统计了

replacements:

如果cache满了，就必须replace

如果你需要向一个已经满容量的组中插入一个缓存行，那么必须驱逐（evict）其中一个缓存行。在直接映射缓存的情况下，驱逐很容易，因为每个组中最多只有一个缓存行。当缓存具有更高的相联度时，就有必要选择一个缓存行进行替换。在本次作业中，你将实现一个 LRU（最近最少使用）替换策略。实现 LRU 的一种方法是，根据缓存行被引用的顺序，保持每个组中的链表有序。这可以通过每次引用缓存行时将其从链表中移除，然后重新插入到链表的头部来完成。在这种情况下，你应该总是驱逐位于链表尾部的缓存行。

要构建组相联缓存并实现上述 LRU 替换策略，你应该使用 `cache.c` 模块中提供的两个例程 `delete` 和 `insert`。`delete` 从链表中移除一个项，而 `insert` 在链表的头部插入一个项。这两个例程都假定一个双向链表（我们的数据结构提供了这一点），并接受三个参数：一个头指针（通过引用传递），一个尾指针（通过引用传递），以及一个要插入或删除的缓存行的指针（通过值传递）。

最后一个提示：如果你实现了一个可以配置相联度的组相联缓存，那么你也已经实现了一个全相联（fully associative）缓存。全相联缓存只是一个 N 路组相联缓存，其中只有 1 个组，而 N 是缓存中的总缓存行数。