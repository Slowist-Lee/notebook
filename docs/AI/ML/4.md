当然，我们接着前面的笔记，将这几页PPT的内容也整理成一份完整的学习指南。

---

#### 6. 完整的反向传播训练流程

前面的内容我们详细推导了反向传播算法中最重要的“误差项” $\delta$ 以及如何用它来计算梯度。现在，我们把所有步骤串联起来，看看一个完整的神经网络训练过程是怎样的。

> [!note] 训练流程概览
>
> **请在这里插入第一页和第二页的图片**
>
> 整个训练过程可以概括为以下几个核心步骤：初始化参数 ->（前向计算 -> 反向传播计算梯度 -> 更新参数）-> 循环迭代。

下面我们来详细分解每一步。

##### (1) 初始化 (Initialization)

在开始训练之前，我们需要给网络中的所有参数一个初始值。

*   **做什么？** 随机设置所有层的权重 $\omega_{ji}^{(m)}$ 和偏置 $b_j^{(m)}$ 的值。
*   **为什么是随机的？** 如果所有权重都初始化为相同的值（比如0），那么在同一层的所有神经元在训练过程中将会有完全相同的行为，这会严重限制网络的学习能力。随机初始化打破了这种对称性。

##### (2) 前向计算 (Forward Calculation)

这一步是让数据在网络中“走”一遍，从输入得到预测输出。

*   **输入：** 一个训练样本 $X$。
*   **过程：**
    1.  将输入样本 $X$ 赋值给输入层的激活值：$a^{(0)} = X$。
    2.  从第一层 ($m=1$) 开始，逐层向前计算，直到最后一层 ($m=L$):
        *   计算第 $m$ 层的加权输入：$z^{(m)} = \omega^{(m)} a^{(m-1)} + b^{(m)}$
        *   通过激活函数得到该层的输出：$a^{(m)} = \varphi(z^{(m)})$
    3.  最后一层的输出 $a^{(L)}$ 就是网络对输入 $X$ 的预测值 $y$。
*   **关键：** 在这个过程中，需要**保存每一层的加权输入 $z^{(m)}$ 和激活值 $a^{(m)}$**，因为这些值在接下来的反向传播步骤中会用到。

##### (3) 反向传播 (Backpropagation)

这是算法的核心，目的是计算出损失函数对网络中每一个参数的梯度。

1.  **计算损失：** 首先，根据前向计算得到的预测值 $y$ 和真实标签 $Y$，计算总误差 $E$。
    $$
    E = \frac{1}{2} \|y - Y\|^2 = \frac{1}{2} \sum_{i=1}^{S_L} (y_i - Y_i)^2
    $$

2.  **反向计算误差项 $\delta$：**
    *   **对于输出层 (L层)：**
        $$
        \delta_i^{(L)} = (y_i - Y_i) \varphi'(z_i^{(L)})
        $$
    *   **对于隐藏层 (从 L-1 层反向到第2层)：**
        $$
        \delta_i^{(m-1)} = \left( \sum_{j=1}^{S_m} \delta_j^{(m)} \omega_{ji}^{(m)} \right) \varphi'(z_i^{(m-1)})
        $$

3.  **计算梯度：** 利用计算出的误差项 $\delta$ 和前向计算中保存的激活值 $a$，计算每个参数的梯度。
    *   **对权重的梯度：**
        $$
        \frac{\partial E}{\partial \omega_{ji}^{(m)}} = \delta_j^{(m)} a_i^{(m-1)}
        $$
    *   **对偏置的梯度：**
        $$
        \frac{\partial E}{\partial b_j^{(m)}} = \delta_j^{(m)}
        $$

> [!success] 回顾
> 是不是觉得这些公式很眼熟？没错！这些就是我们第一部分笔记中花费大量篇幅推导出来的核心公式。现在我们把它们放在了算法流程的“计算梯度”这一步。

##### (4) 更新参数 (Apply Gradients)

计算出梯度之后，我们就可以沿着梯度的反方向去更新权重和偏置，从而让损失函数 $E$ 变小。这就是**梯度下降法**。

> [!note] 参数更新
>
> **请在这里插入第三页的图片**
>
> *   **权重更新规则：**
>     $$
>     \omega_{ji}^{(m)} = \omega_{ji}^{(m)} - \alpha \frac{\partial E}{\partial \omega_{ji}^{(m)}}
>     $$
> *   **偏置更新规则：**
>     $$
>     b_j^{(m)} = b_j^{(m)} - \alpha \frac{\partial E}{\partial b_j^{(m)}}
>     $$
>
> *   $\alpha$ 是 **学习率 (learning rate)**，它是一个超参数，控制了我们每一步更新的“步子”迈多大。
>     *   如果 $\alpha$太大，可能会导致在最优点附近来回震荡，无法收敛。
>     *   如果 $\alpha$太小，收敛速度会非常慢。
> *   **为什么要减去梯度？** 梯度方向是函数值**上升最快**的方向，我们想要最小化损失，所以要沿着梯度的**反方向**更新参数。

##### (5) 循环迭代 (Iteration)

神经网络的训练不是一步到位的，而是一个反复迭代、逐步优化的过程。

*   **做什么？** 重复执行第 (2) 步到第 (4) 步。也就是说，对于训练集中的每一个（或每一批）样本，都执行一次“前向计算 -> 反向传播 -> 更新参数”的流程。
*   **何时停止？**
    *   PPT中提到 “till all gradients are zeros”，这是一个理论上的理想情况，意味着找到了损失函数的（局部）最小值。
    *   在实际操作中，我们通常会设置其他的停止条件，比如：
        *   **达到预设的迭代次数 (epochs)**：比如把整个训练数据集过100遍。
        *   **损失函数的值不再显著下降**：当损失曲线变得平缓时，说明模型已经收敛。
        *   **在验证集上的性能不再提升**：为了防止过拟合，我们可以在训练中监控模型在验证集上的表现，如果表现开始变差就提前停止。

---

> [!summary] 总结：反向传播训练算法 "菜谱"
>
> 把训练一个神经网络想象成做菜，这里的步骤就是菜谱：
>
> 1.  **备料 (Initialization)**: 随机准备好你的锅碗瓢盆（权重 $\omega$ 和偏置 $b$）。
> 2.  **试菜 (Forward Calculation)**: 把一份食材（输入数据 $X$）放进锅里，按照流程炒一遍，得到一道菜（预测输出 $y$）。
> 3.  **品尝与反思 (Backpropagation)**: 尝一下味道（计算损失 $E$），然后从这道菜的味道开始，一步步反思是哪一步的油盐酱醋（权重和偏置）放多了还是放少了（计算梯度 $\frac{\partial E}{\partial \omega}, \frac{\partial E}{\partial b}$）。
> 4.  **调整配方 (Apply Gradients)**: 根据反思的结果，稍微调整一下油盐酱醋的用量（更新参数 $\omega, b$）。
> 5.  **不断尝试 (Iteration)**: 不断地用新的食材（下一个训练样本）重复“试菜->反思->调整”的过程，直到你对自己的厨艺（模型性能）满意为止。